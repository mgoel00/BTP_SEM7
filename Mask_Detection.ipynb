{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Mask Detection using MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Defining our data generators\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "img_rows, img_cols = 128,128\n",
    "batch_size = 16\n",
    "\n",
    "train_data_dir = './dataset/train'\n",
    "validation_data_dir = './dataset/validation'\n",
    "\n",
    "# Let's use some data augmentation and define our generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      shear_range=0.3,\n",
    "      zoom_range=0.3,\n",
    "      width_shift_range=0.4,\n",
    "      height_shift_range=0.4,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "train_images = train_generator.samples\n",
    "validation_images = validation_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    We will use the pretrained MobileNet to which we will add our own network of FC layers.\n",
    "    We then train the new model formed for the additional layers.\n",
    "\n",
    "\"\"\"\n",
    "from keras.applications import MobileNet\n",
    "\n",
    "# Lets load the MobileNet model without the top or FC layers\n",
    "MobileNet = MobileNet(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))\n",
    "\n",
    "# Layers are set to be trainable as True by default but lets make them untrainable\n",
    "for layer in MobileNet.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Let's check our layers \n",
    "for (i,layer) in enumerate(MobileNet.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTopModelMobileNet(bottom_model):\n",
    "    \"\"\"\n",
    "    \n",
    "        Creates the head of the model that will be \n",
    "        placed ontop of the bottom layers\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    top_model = bottom_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(512,activation='relu')(top_model)\n",
    "    top_model = Dense(128,activation='relu')(top_model)\n",
    "    top_model = Dense(64,activation='relu')(top_model)\n",
    "    \n",
    "    top_model = Dense(2,activation='sigmoid')(top_model)\n",
    "    return top_model\n",
    "\n",
    "\n",
    "#Combining the model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "FC_Head = addTopModelMobileNet(MobileNet)\n",
    "\n",
    "model = Model(inputs = MobileNet.input, outputs = FC_Head)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training our model\n",
    "#One could do some tweakings!\n",
    "from keras.optimizers import RMSprop, SGD,Adadelta\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"face_mask_detector.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, verbose = 1, min_delta = 0.0001)\n",
    "\n",
    "callbacks = [earlystop, checkpoint, reduce_lr]\n",
    "\n",
    "nb_train_samples = train_images\n",
    "nb_validation_samples = validation_images\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = 'rmsprop',\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our model\n",
    "from keras.models import load_model\n",
    "classifier = load_model('face_mask_detector.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test on realtime video\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "img_rows, img_cols = 128,128\n",
    "# A function that puts the predicted class lables on the parametric image frames\n",
    "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               font_scale=0.8, thickness=1):\n",
    "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "    x, y = point\n",
    "    cv2.rectangle(image, (x, y - size[1]), (x + size[0], y), (255, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness, lineType=cv2.LINE_AA)\n",
    "    \n",
    "#Define our prediction dictionary\n",
    "face_classes = {0: 'with_mask', 1: 'without_mask'}\n",
    "img_size = 128\n",
    "\n",
    "detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    preprocessed_faces = []           \n",
    " \n",
    "    input_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img_h, img_w, _ = np.shape(frame)\n",
    "    detected = detector.detectMultiScale(frame)\n",
    "    faces = np.empty((len(detected), img_size, img_size, 3))\n",
    "   \n",
    "    if len(detected) > 0:\n",
    "        \n",
    "        for f in detected:\n",
    "            \n",
    "            # Obtain the coordinates of the detected face and draw a bounding box\n",
    "            x1, y1, w, h = [v for v in f]\n",
    "            cv2.rectangle(frame, (x1, y1), (x1+w,y1+h), (255, 0, 0), 2)\n",
    "            face =  frame[y1:y1+h, x1:x1+w, :]\n",
    "            face = cv2.resize(face, (img_rows,img_cols))\n",
    "            face = face.astype(\"float32\") / 255.0\n",
    "            face = np.expand_dims(face, axis=0)\n",
    "            preprocessed_faces.append(face)\n",
    "\n",
    "        \n",
    "        # Make predictions for the detected face \n",
    "        face_labels = []\n",
    "        for i, d in enumerate(detected):\n",
    "            preds = classifier.predict(preprocessed_faces[i])[0]\n",
    "            face_labels.append(face_classes[np.argmax(preds,axis=0)])\n",
    "#             print(preds)\n",
    "        \n",
    "        # Putting labels on frames\n",
    "        for i, d in enumerate(detected):\n",
    "            label = \"{}\".format(face_labels[i])\n",
    "#             print(label)\n",
    "            draw_label(frame, (x1,y1), label)\n",
    "    \n",
    "    #Display the results\n",
    "    cv2.imshow(\"Face Mask Recognition\", frame)\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2908185e-05 9.9999905e-01]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "without_mask\n",
      "without_mask\n",
      "without_mask\n"
     ]
    }
   ],
   "source": [
    "#You can use some images for testing also using this part of the code\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# A function that puts the predicted class lables on the parametric image frames\n",
    "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               font_scale=0.8, thickness=1):\n",
    "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "    x, y = point\n",
    "    cv2.rectangle(image, (x, y - size[1]), (x + size[0], y), (255, 0, 0), cv2.FILLED)\n",
    "    cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness, lineType=cv2.LINE_AA)\n",
    "    \n",
    "#Define our prediction dictionary\n",
    "face_classes = {0: 'with_mask', 1: 'without_mask'}\n",
    "img_size = 128\n",
    "\n",
    "detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "frame = cv2.imread('E:\\Others\\Shimla Manali\\IMG_20210910_134647.jpg')\n",
    "frame = cv2.resize(frame,(1080,720))\n",
    "preprocessed_faces = []           \n",
    "\n",
    "input_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "img_h, img_w, _ = np.shape(frame)\n",
    "detected = detector.detectMultiScale(frame)\n",
    "faces = np.empty((len(detected), img_size, img_size, 3))\n",
    "\n",
    "if len(detected) > 0:\n",
    "\n",
    "    for f in detected:\n",
    "\n",
    "        # Obtain the coordinates of the detected face and draw a bounding box\n",
    "        x1, y1, w, h = [v for v in f]\n",
    "        cv2.rectangle(frame, (x1, y1), (x1+w,y1+h), (255, 0, 0), 2)\n",
    "        face =  frame[y1:y1+h, x1:x1+w, :]\n",
    "        face = cv2.resize(face, (img_rows,img_cols))\n",
    "        face = face.astype(\"float32\") / 255.0\n",
    "        face = np.expand_dims(face, axis=0)\n",
    "        preprocessed_faces.append(face)\n",
    "\n",
    "\n",
    "    # Make predictions for the detected face \n",
    "    face_labels = []\n",
    "    for i, d in enumerate(detected):\n",
    "        preds = classifier.predict(preprocessed_faces[i])[0]\n",
    "        face_labels.append(face_classes[np.argmax(preds,axis=0)])\n",
    "        print(preds)\n",
    "\n",
    "    # Putting labels on frames\n",
    "    for i, d in enumerate(detected):\n",
    "        label = \"{}\".format(face_labels[i])\n",
    "        print(label)\n",
    "        draw_label(frame, (x1,y1), label)\n",
    "\n",
    "# Display the results\n",
    "cv2.imshow(\"Face Recognition\", frame)\n",
    "cv2.waitKey(0) == 13\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
